11.05.2025

I ve figured out that there are 6 type of calculating with percentage which are :

1. Basic part, whole, miltiplying by 100
2  Aggregation
3. With conditions
4. Percentage change
5. Cumulative %
6. Weighted %


So at the moment I am sharpening my knowledge on all of these calculations starting the the basics one first. 

tomorrow I need to analyze the dataset from teh the metabease


26.05.2025

Today I coded on the project of the airline and only the 7th and 8th task is left to finish it. I am certain by tomorrow I will get it done.

27.05.25


Today I am working on the codecademy taks 7 and 8 to complete it today. It takes too much time to upload and work there. From now on I am 
thinking where I dy any task I fist complete it in jupyter notebook and at codecademy one by one. In order to upload also my work in 
codecademy.

AI feedback on my project:


dasdasdas


1. Ensure that all tasks are completed as per the project requirements. For instance, Task 6 could include more analysis on how the 
number of passengers changes with flight length, rather than just visualizing it. 

(meaining : I need to digg deeper to get more insights about the  issue)


2. Consider using functions to encapsulate repetitive code blocks, such as plotting functions. This will make your code more modular
and easier to maintain.

example: 

def plot_histogram(data, title, xlabel, ylabel):
    sns.histplot(data)
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.show()
    plt.clf()

plot_histogram(flight.coach_price, "1 : Boxplot of Coach Price", "Price", "Frequency")


28.05

Today I had an hour of studying . 


29.05

Today I finished my EDA analysis with codecademy. Got my certificate. 



8.06. 

Today I have a lot of problem with github I spent a hour try to fix my github stil couldnt do it. So but anyway in the morning I spent an hour
to do a deep work. That is already a good sign that I am doing. 

9.06.

    Today I am having 2h of deep work to intentionally  work on my project. I worked enough and I am seeing progress. Need to work more
and more. 

27.06

Today I am coming back to my coding in python doing EDA Analysis. So continuing my job. It seems and feels so difficult to me. I dont know
but anyway I am doing it. Lets suffer I am not enjoying it at all. But anyway, I dont have any other choice but to code to earn more and 
make a better life. I better start to enjoying it more than complain about it because I dont have any other choice but to learn more. 




22.07.25

Today is 22 of July meaning I skipped 27 day of the project and I am really embarassed that I escaped myself. 
So today I am going to continue with the Airbnb project. 

24. 07

I skipped one day but it was great day did 2h and 20minutes of deep work and I saw some progress . I need to do more and more 
that's really important.


25.07

Today is my day off but I am commited to dedicate 6h of work in my project. I am starting it. Lets go!

_____________________________________________________________________________________________________________

listings_lisbon.loc[:,'availability_range'] = pd.cut(
    listings_lisbon['availability_365'], 
    bins=[-1,0,180, 364, 365],
    labels = ['Unavailable', 'Seasonal', 'Mostly Available', 'Always Available']
)

_________________________________________________________________________________________________________________

My goal is at the moment to understand this code. 

So to my knowledge we are accessing the dataframe listings_lisbon here using the (,loc) indexer to create a new column 
called availability_range and choosing the all rows . By the pd.cut() function of the pandas library to categorize the availablity_365
column. 


26.07

Today is another day I am working  on my project. I am stil doing an "univariate analysis" of the availability_265 column meaning. Analyzing
the yearly availibilty of the column. Today in the morning I finished the visualization part. At the same time I am curious abou the 
technical part of the solution. I am trying to understand every bits of the code what it does for instance.

28.07 

For some reason I am skipping one day . I don't know why is this the case. Anyway lets get start to work. Now we are 
ready to put 3h of work into todays agenda. We are moving slowly but intentionally. Lets go.

30. 07

Yesterday I did some work which was 4h and did not register in Github. Today I am moving to
the 3rd hours of data woork. Now I am trying to finish the last part of numerical univariate 
analysis with the airbnb data. 

31.
    Yesterday I finished the univariate analysis with the numerical values so now this 3hours I am going to dedicate to the 
categorical variables of doing inivariate analysis. 

1.08.25

Finally I finished the Univariate Analysis with the Airbnb dataset congratulations. On the 1st phase Need to do more. I spent 3h doing that.
1h Rest and then continue.

Continued 2h more so in total 5hours of deep work. 

I am managing to do greatly the bivariate analysis. Today at night continue 1hour. Good luck with my entry. 

2.08. 

Today I only worked 1h on the BA. So I am on the right track....
Tomorrow is another day.

3.08. 

Today I am learningn in the meantime about standard deviation in statistics. In the same time while coding. I got some ideas about it.
Still working on my bevariate analysis. 

6.08 
So basically I skipped only yesterday by not doing the work. Day 4th of august but did not tegister here. Today I am working on the 
scatterplot. How two variables are analyzed in scatterplot. I am really confused with my scatterplot result, these are the questions allow
me step by step to understand :

1. Are the two columns that I have ready for scatterplot ? how can I check them ? 

        The fist thing is to check the data types of price_per_night and number_of_reviews, the result is PRICE_PER_NIGH is FLOAT64 and
NUMBER_OF_REVIEWS is INT64.

Feedback:
- Having one column as float and the other as integer is completely fine for scatterplots.
- What matters more is that the columns contain clean numeric data without strings or missing values.

2. Check for missing values ? 
        There is not missing values.

3.Check for extreme outliers

    price_per_night  number_of_reviews
count    645506.000000      645506.000000
mean         63.210394         185.849895
std         224.025612         154.457660
min           0.226667           1.000000
25%          28.333333          69.000000
50%          42.000000         147.000000
75%          69.500000         266.000000
max       10010.000000        1718.000000

    The shows that there are some extreme values on both columns in price_per_night and number_of_reviews. The quesion is what I need
to do to understand better the relationship between this 2 variables .

4. Deal with Extreme Outliers ? 
    My answer to dealing with extreme outliers are to use the quantile function and filter the only 99% of the values in each column. Then
plot the scatter. What would you say to this. And also is it much practical to save the filtered data in a new variable or I can filter it
on the scatterplot ?

5. Isnt there a problem when the price have float value like 0.4 or 0.6 and reviews interger 1,2,4 and etc. 
? Won't it give us inaccurate plot?
                Feedback: 
- Float for price + int for reviews = perfectly fine for scatterplots.
- Plotting will be accurate, because itâ€™s just numeric coordinates.

6. Understand the purpose of the scatterplot more ? 

-A scatterplot normally has pairs (x, y), and each dot represents both values together, not separate dots for each variable.
-Continue : How bring me an example , overall I got it. 

7. So now at the moment i have the plot which has a lot of data points, visually it seems that the listings from 0 to 150 have high 
reviews since this is included in the lower price categoty after the increase in price the reviews decline, but its a lot of data points
I dont say for sure the variables relationship. 

8. Now I did the random sampling, how would get the correlation , from the noice. now I would have 63308 data points which is 10% of the 
data, which correlation I use to test it ? 

                                                        8/08/25
    Today is another day of august I am stuck in the bevariate analysis of two variabels. At the moment I am plotting price and 
availability_365 columns to check their relationship. 

1. Why my price per night have strange minimum because  I did the following : listings_lisbon.loc[:,'price_per_night']=listings_lisbon
'price'] / listings_lisbon['minimum_nights']. To get much accurate pice number I divided the price to minimum nights for instance if there
was price 100 and the minimum nights 2 the price_per_night gave me 50. Correct me in this part if I am on the right pay or to draw the
relationship its better to stick to general price column and why ?

2. Now that we filtered to max 30 minimum noghts so we know that therr is not going to be strange numbers,
why are we still filtering the price_per_night >10 still, and if the 99% of the 
price_per_night lies to 305 why filter to 200 ? and why avalibilty >10 ?

My ovservation:

1. The data points are partially clustered around 150 in the price part mostly,
to some extent there is a trend upward but there are a lot data poitns that is not
very clear. 

2. Probably there is slight positive correlation. The plot shows with the trend line
is going upward slightly due to the increase of price and availabilty simultaniously. 

3. Certainly there are danse groups around price 0 to 100, very densly like . 

4. Mainly the outliers are the far from the main cluster which have high price, and
also high availability. 

5. The data is I would say mostly concentrated in a small price range which is 
around 0 to 100 , the availabity is skewed toward high mea. 

Simple question: Fist when we plot a scatterplot and the data points are more than 10K, should I immediatly sample it to 3K, then interpret
it and then  check the statisticall correlatio with Pearson and Spearman as a rule ? or there is another way of approaching ? 


18.08.25

I am puzzled today with the categorical/binary variable how do generally it is measured over time ? So I have a date column, the metric name
which consist of Yes and No. I just want to understand the trends of the yes and no over time.

Got it. So the the planned the day is done! I did it. 


20.08.25

Today is a good day I was trying to show my categorical variable in chart by showing the weekly progress over time. In particular, if I
was able to plan my day weekly. With the column chart I managed to show the weekly trend. I set the target and also the moving average of 4
weeks where it smoothes the flactuations. The next step is now to get another categorical varaible chart which is Diet followed. Yes and No 
value, I am going to show it also in a weekly trend to see the 7th days per week how often I follow my diet. And will continue doing with 
other categorical variabeles. 


22.08

I did some work today. Take a shower and work an hour on tracking  tracking the workout. 

23.08

Today I finished with the Planned the day and now I need to continue with the Journal. 





